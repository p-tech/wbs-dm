{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-tech/wbs-dm/blob/main/Tidy_Data/Tidy_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYoCzD8T3W2P"
      },
      "source": [
        "# Tidy Data in Python\n",
        "by [Jean-Nicholas Hould](http://www.jeannicholashould.com/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cU-S2RQt3W2Q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import glob\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qbarJzD3W2R"
      },
      "source": [
        "## Column headers are values, not variable names\n",
        "\n",
        "A dataset is in a wide format where important data values are stored in column names instead of inside the table as proper values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBKpnmdK3W2R"
      },
      "source": [
        "### Pew Research Center Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8F44Scf3W2R"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/pew-raw.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`formatted_df = pd.melt(df,[\"religion\"], var_name=\"income\", value_name=\"freq\")`\n",
        "\n",
        "pd.melt() is used to convert wide-format data into long-format data.\n",
        "\n",
        "\"religion\" is kept as an identifier variable (it stays the same).\n",
        "\n",
        "Other column names (except \"religion\") are converted into values under a new column called \"income\".\n",
        "\n",
        "The corresponding values from those columns are placed in a new column called \"freq\"."
      ],
      "metadata": {
        "id": "Q4JLdPRw5bVv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXoZmstr3W2S"
      },
      "outputs": [],
      "source": [
        "formatted_df = pd.melt(df,[\"religion\"], var_name=\"income\", value_name=\"freq\")\n",
        "formatted_df = formatted_df.sort_values(by=[\"religion\"])\n",
        "formatted_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first column is the original index for the data in the table.  If we want to reindex the data use the following code."
      ],
      "metadata": {
        "id": "LmNANz9N7tLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_df = formatted_df.sort_values(by=[\"religion\"]).reset_index(drop=True)\n",
        "formatted_df.head(10)"
      ],
      "metadata": {
        "id": "U5S8S7VQ7nAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th8mUGBZ3W2S"
      },
      "source": [
        "### Billboard Top 100 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset represents the weekly rank of songs from the moment they enter the Billboard Top 100 to the subsequent 75 weeks.\n",
        "\n",
        "Problems:\n",
        "\n",
        "The columns headers are composed of values: the week number (x1st.week, …)\n",
        "\n",
        "If a song is in the Top 100 for less than 75 weeks, the remaining columns are filled with missing values."
      ],
      "metadata": {
        "id": "-tE_R-cX8sLM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlzARWuX3W2S"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/billboard.csv\", encoding=\"mac_latin2\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tidy version of this dataset is one without the week’s numbers as columns but rather as values of a single column.\n",
        "\n",
        "In order to do so, we’ll melt the weeks columns into a single date column. We will create one row per week for each record.\n",
        "\n",
        "If there is no data for the given week, we will not create a row."
      ],
      "metadata": {
        "id": "ppHNU1ES9J1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8tNzf-2aEmCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What’s Happening?\n",
        "\n",
        "The dataset originally has week numbers as column headers (e.g., \"wk1\", \"wk2\", etc.), where each row represents a song.\n",
        "\n",
        "pd.melt() converts the dataset from wide format to long format, keeping \"year\", \"artist.inverted\", \"track\", etc., as identifier variables.\n",
        "\n",
        "All week columns (wk1, wk2, etc.) are melted into one column called \"week\", and their values go into the \"rank\" column.\n",
        "\n",
        "The \"week\" column originally contains text like \"wk1\", \"wk2\", etc.\n",
        "\n",
        "str.extract('(\\d+)') extracts only the numeric part (1, 2, 3, etc.).\n",
        "astype(int)\n",
        "\n",
        "converts it from a string to an integer."
      ],
      "metadata": {
        "id": "-CSs_LYMEA1C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKFmGve43W2S"
      },
      "outputs": [],
      "source": [
        "# Melting\n",
        "id_vars = [\"year\",\n",
        "           \"artist.inverted\",\n",
        "           \"track\",\n",
        "           \"time\",\n",
        "           \"genre\",\n",
        "           \"date.entered\",\n",
        "           \"date.peaked\"]\n",
        "\n",
        "df = pd.melt(frame=df,id_vars=id_vars, var_name=\"week\", value_name=\"rank\") # Changed \"rank\" to \"value\"\n",
        "\n",
        "# Formatting\n",
        "df[\"week\"] = df['week'].str.extract('(\\d+)', expand=False).astype(int)\n",
        "\n",
        "# Remove rows where value is NaN\n",
        "df = df.dropna(subset=['rank'])\n",
        "\n",
        "#.loc is a label-based indexing method in pandas. It's more explicit about how you are accessing data in the DataFrame.\n",
        "#The colon : before the comma indicates that you want to select all rows.\n",
        "#\"rank\" after the comma indicates that you want to select the column labeled \"rank\".\n",
        "\n",
        "df.loc[:, \"rank\"] = df[\"rank\"].astype(int)\n",
        "#df[\"rank\"] = df[\"rank\"].astype(int) # Changed \"rank\" to \"value\"\n",
        "\n",
        "# Cleaning out unnecessary rows\n",
        "df = df.dropna()\n",
        "\n",
        "# Create \"date\" columns\n",
        "df['date'] = pd.to_datetime(df['date.entered']) + pd.to_timedelta(df['week'], unit='w') - pd.DateOffset(weeks=1)\n",
        "\n",
        "df = df[[\"year\",\n",
        "         \"artist.inverted\",\n",
        "         \"track\",\n",
        "         \"time\",\n",
        "         \"genre\",\n",
        "         \"week\",\n",
        "         \"rank\", # Changed \"rank\" to \"value\"\n",
        "         \"date\"]]\n",
        "df = df.sort_values(ascending=True, by=[\"year\",\"artist.inverted\",\"track\",\"week\",\"rank\"]) # Changed \"rank\" to \"value\"\n",
        "\n",
        "# Assigning the tidy dataset to a variable for future usage\n",
        "billboard = df\n",
        "\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following up on the Billboard dataset, we’ll now address the repetition problem of the previous table.\n",
        "\n",
        "Problems:\n",
        "\n",
        "Multiple observational units (the song and its rank) in a single table."
      ],
      "metadata": {
        "id": "3KZV27-OFci4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4UeZ-sm3W2T"
      },
      "source": [
        "## Multiple types in one table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVX817hb3W2T"
      },
      "outputs": [],
      "source": [
        "songs_cols = [\"year\", \"artist.inverted\", \"track\", \"time\", \"genre\"]\n",
        "songs = billboard[songs_cols].drop_duplicates()\n",
        "songs = songs.reset_index(drop=True)\n",
        "songs[\"song_id\"] = songs.index\n",
        "songs.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What’s Happening?\n",
        "\n",
        "pd.merge() combines the billboard and songs datasets based on common columns.\n",
        "\n",
        "The on=[...] argument specifies the matching columns that should be the same in both datasets.\n",
        "\n",
        "The resulting dataset (ranks) will contain rows where both datasets have matching values for:\n",
        "\n",
        "year\n",
        "artist.inverted (artist name formatted as Last, First)\n",
        "track (song name)\n",
        "time (track duration)\n",
        "genre (music genre)\n",
        "\n",
        "Why Merge?\n",
        "\n",
        "The songs dataset probably contains extra song details (e.g., song_id), which are not present in billboard.\n",
        "\n",
        "By merging, we connect ranking data (billboard) with song metadata (songs)."
      ],
      "metadata": {
        "id": "Vn8bb-atF3yE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPhUXaj33W2T"
      },
      "outputs": [],
      "source": [
        "ranks = pd.merge(billboard, songs, on=[\"year\",\"artist.inverted\", \"track\", \"time\", \"genre\"])\n",
        "ranks = ranks[[\"song_id\", \"date\",\"rank\"]]\n",
        "ranks.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "N-TWuiUj3W2T"
      },
      "source": [
        "## Multiple variables stored in one column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi3W5SUD3W2T"
      },
      "source": [
        "### Tubercolosis Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpse7yJx3W2T"
      },
      "source": [
        "This dataset documents the count of confirmed tuberculosis cases by country, year, age and sex.\n",
        "\n",
        "Problems:\n",
        "\n",
        "Some columns contain multiple values: sex and age.\n",
        "\n",
        "Mixture of zeros and missing values NaN. This is due to the data collection process and the distinction is important for this dataset.\n",
        "\n",
        "A few notes on the raw data set:\n",
        "\n",
        "- The columns starting with \"m\" or \"f\" contain multiple variables:\n",
        "    - Sex (\"m\" or \"f\")\n",
        "    - Age Group (\"0-14\",\"15-24\", \"25-34\", \"45-54\", \"55-64\", \"65\", \"unknown\")\n",
        "- Mixture of 0s and missing values(\"NaN\"). This is due to the data collection process and the distinction is important for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdCjQoGQ3W2T"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/tb-raw.csv\")\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to tidy this dataset, we need to remove the different values from the header and unpivot them into rows.\n",
        "\n",
        "We’ll first need to melt the sex + age group columns into a single one.\n",
        "\n",
        "Once we have that single column, we’ll derive three columns from it: sex, age_lower and age_upper.\n",
        "\n",
        "With those, we’ll be able to properly build a tidy dataset."
      ],
      "metadata": {
        "id": "SN01r8XwKP6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`df[\"sex_and_age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\", expand=False)`\n",
        "\n",
        ".str.extract() is a pandas string method used to extract substrings that match a regular expression (regex).\n",
        "\n",
        "\\D - match non-digit characters\n",
        "\n",
        "\\d+ - get following digits\n",
        "\n",
        "\\d{2} - get last 2 digits\n",
        "\n",
        "expand=False ensures the extracted data is returned as a DataFrame instead of a DataFrame with named columns."
      ],
      "metadata": {
        "id": "OHCpNQa1Iop8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6P30JxnO3W2T"
      },
      "outputs": [],
      "source": [
        "df = pd.melt(df, id_vars=[\"country\",\"year\"], value_name=\"cases\", var_name=\"sex_and_age\")\n",
        "\n",
        "# Extract Sex, Age lower bound and Age upper bound group\n",
        "tmp_df = df[\"sex_and_age\"].str.extract(\"(\\D)(\\d+)(\\d{2})\", expand=False)\n",
        "\n",
        "# Name columns\n",
        "tmp_df.columns = [\"sex\", \"age_lower\", \"age_upper\"]\n",
        "\n",
        "# Create `age`column based on `age_lower` and `age_upper`\n",
        "tmp_df[\"age\"] = tmp_df[\"age_lower\"] + \"-\" + tmp_df[\"age_upper\"]\n",
        "\n",
        "# Merge\n",
        "df = pd.concat([df, tmp_df], axis=1)\n",
        "\n",
        "# Drop unnecessary columns and rows\n",
        "df = df.drop(['sex_and_age',\"age_lower\",\"age_upper\"], axis=1)\n",
        "df = df.dropna()\n",
        "df = df.sort_values(ascending=True,by=[\"country\", \"year\", \"sex\", \"age\"])\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V6LSKYW3W2T"
      },
      "source": [
        "## Variables are stored in both rows and columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lceZgY_3W2T"
      },
      "source": [
        "### Global Historical Climatology Network Dataset\n",
        "\n",
        "This dataset represents the daily weather records for a weather station (MX17004) in Mexico for five months in 2010.\n",
        "\n",
        "Problems:\n",
        "\n",
        "Variables are stored in both rows (tmin, tmax) and columns (days)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxYu8O-U3W2U"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./data/weather-raw.csv\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsyqGutW3W2U"
      },
      "outputs": [],
      "source": [
        "df = pd.melt(df, id_vars=[\"id\", \"year\",\"month\",\"element\"], var_name=\"day_raw\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make this dataset tidy, we want to move the three misplaced variables (tmin, tmax and days) as three individual columns: tmin. tmax and date.\n",
        "\n",
        "d - Matches the letter \"d\" exactly.\n",
        "\n",
        "(\\d+) - Captures one or more digits (the day number).\n",
        "\n",
        "`df[[\"year\",\"month\",\"day\"]] = df[[\"year\",\"month\",\"day\"]].apply(lambda x: pd.to_numeric(x, errors='ignore'))`\n",
        "\n",
        "take the year / month / day - converts to a numeric and stores as date.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6OlJHH-fLuH7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul_KOYVK3W2U"
      },
      "outputs": [],
      "source": [
        "# Extracting day\n",
        "df[\"day\"] = df[\"day_raw\"].str.extract(\"d(\\d+)\", expand=False)\n",
        "df[\"id\"] = \"MX17004\"\n",
        "\n",
        "# To numeric values\n",
        "df[[\"year\",\"month\",\"day\"]] = df[[\"year\",\"month\",\"day\"]].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
        "\n",
        "# Creating a date from the different columns\n",
        "def create_date_from_year_month_day(row):\n",
        "    return datetime.datetime(year=row[\"year\"], month=int(row[\"month\"]), day=row[\"day\"])\n",
        "\n",
        "df[\"date\"] = df.apply(lambda row: create_date_from_year_month_day(row), axis=1)\n",
        "df = df.drop(['year',\"month\",\"day\", \"day_raw\"], axis=1)\n",
        "df = df.dropna()\n",
        "\n",
        "# Unmelting column \"element\"\n",
        "df = df.pivot_table(index=[\"id\",\"date\"], columns=\"element\", values=\"value\")\n",
        "df.reset_index(drop=False, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "OmpqH9eG3W2U"
      },
      "source": [
        "## One type in multiple tables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f1o2afq3W2U"
      },
      "source": [
        "### Baby Names in Illinois\n",
        "\n",
        "Problems:\n",
        "\n",
        "The data is spread across multiple tables/files.\n",
        "\n",
        "The “Year” variable is present in the file name.\n",
        "\n",
        "In order to load those different files into a single DataFrame, we can run a custom script that will append the files together.\n",
        "\n",
        "Furthermore, we’ll need to extract the “Year” variable from the file name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEHyW4zp3W2U"
      },
      "outputs": [],
      "source": [
        "def extract_year(string):\n",
        "    match = re.match(\".+(\\d{4})\", string)\n",
        "    if match != None: return match.group(1)\n",
        "\n",
        "path = './data'\n",
        "allFiles = glob.glob(path + \"/201*-baby-names-illinois.csv\")\n",
        "frame = pd.DataFrame()\n",
        "df_list= []\n",
        "for file_ in allFiles:\n",
        "    df = pd.read_csv(file_,index_col=None, header=0)\n",
        "    df.columns = map(str.lower, df.columns)\n",
        "    df[\"year\"] = extract_year(file_)\n",
        "    df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "df.head(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}