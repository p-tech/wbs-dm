{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+ynAAxpu7jLDyT6PTWZxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p-tech/wbs-dm/blob/main/sqlite-exercise/Exercise_SQLite_DB_Joins.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1: CREATE the SQLite database;**\n"
      ],
      "metadata": {
        "id": "LNaKuchnQfb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to import the sqlite3 module and create the database and tables.  You'll see this follows the syntax we have used on previous weeks.\n"
      ],
      "metadata": {
        "id": "wUpw9AOgQweW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iMWnVhS8qjx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50c59e7-1b8c-4871-e412-ce96fefb69f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database and tables created successfully!\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "\n",
        "#This statement creates a connection labelled as conn.  This will be used throughout to ensure the consistency for when we start to query the database tables.\n",
        "conn = sqlite3.connect('ecommerce.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_customers (\n",
        "    customer_id VARCHAR(32) PRIMARY KEY,\n",
        "    customer_unique_id VARCHAR(32),\n",
        "    customer_zip_code_prefix INT,\n",
        "    customer_city VARCHAR(255),\n",
        "    customer_state VARCHAR(2)\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_geolocation (\n",
        "    geolocation_zip_code_prefix INT,\n",
        "    geolocation_lat FLOAT,\n",
        "    geolocation_lng FLOAT,\n",
        "    geolocation_city VARCHAR(255),\n",
        "    geolocation_state VARCHAR(2)\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_order_items (\n",
        "    order_id VARCHAR(32),\n",
        "    order_item_id INT,\n",
        "    product_id VARCHAR(32),\n",
        "    seller_id VARCHAR(32),\n",
        "    shipping_limit_date DATETIME,\n",
        "    price FLOAT,\n",
        "    freight_value FLOAT,\n",
        "    PRIMARY KEY (order_id, order_item_id)\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_order_payments (\n",
        "    order_id VARCHAR(32),\n",
        "    payment_sequential INT,\n",
        "    payment_type VARCHAR(50),\n",
        "    payment_installments INT,\n",
        "    payment_value FLOAT,\n",
        "    PRIMARY KEY (order_id, payment_sequential)\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_order_reviews (\n",
        "    review_id VARCHAR(32) PRIMARY KEY,\n",
        "    order_id VARCHAR(32),\n",
        "    review_score INT,\n",
        "    review_comment_title TEXT,\n",
        "    review_comment_message TEXT,\n",
        "    review_creation_date DATETIME,\n",
        "    review_answer_timestamp DATETIME\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_orders (\n",
        "    order_id VARCHAR(32) PRIMARY KEY,\n",
        "    customer_id VARCHAR(32),\n",
        "    order_status VARCHAR(50),\n",
        "    order_purchase_timestamp DATETIME,\n",
        "    order_approved_at DATETIME,\n",
        "    order_delivered_carrier_date DATETIME,\n",
        "    order_delivered_customer_date DATETIME,\n",
        "    order_estimated_delivery_date DATETIME\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_products (\n",
        "    product_id VARCHAR(32) PRIMARY KEY,\n",
        "    product_category_name VARCHAR(255),\n",
        "    product_name_lenght FLOAT,\n",
        "    product_description_lenght FLOAT,\n",
        "    product_photos_qty FLOAT,\n",
        "    product_weight_g FLOAT,\n",
        "    product_length_cm FLOAT,\n",
        "    product_height_cm FLOAT,\n",
        "    product_width_cm FLOAT\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE olist_sellers (\n",
        "    seller_id VARCHAR(32) PRIMARY KEY,\n",
        "    seller_zip_code_prefix INT,\n",
        "    seller_city VARCHAR(255),\n",
        "    seller_state VARCHAR(2)\n",
        ");\n",
        "''')\n",
        "\n",
        "cursor.execute('''\n",
        "CREATE TABLE product_category_translation (\n",
        "    product_category_name VARCHAR(255) PRIMARY KEY,\n",
        "    product_category_name_english VARCHAR(255)\n",
        ");\n",
        "''')\n",
        "\n",
        "#This saves the chnages to the databae.  Up unitl this point the executed SQL statement isn't stored, changes are not immediatley saved.\n",
        "conn.commit()\n",
        "\n",
        "print(\"Database and tables created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2: Check Tables Created:**\n",
        "\n",
        "Run the command to show the database tables created and the structure."
      ],
      "metadata": {
        "id": "bQ8lr_HEViN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "tables = cursor.fetchall()\n",
        "\n",
        "for table_name in tables:\n",
        "    print(f\"Table: {table_name[0]}\")\n",
        "    cursor.execute(f\"PRAGMA table_info({table_name[0]});\")\n",
        "    columns = cursor.fetchall()\n",
        "    for col in columns:\n",
        "        print(f\"  Column: {col[1]}, Type: {col[2]}, NotNull: {col[3]}, DefaultVal: {col[4]}, PrimaryKey: {col[5]}\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7YAxyXoB9rN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3: Upload Files:**\n",
        "\n",
        "Run this box multiple times to upload the relevant csv files. Or drag the files across to the Files window from your desktop."
      ],
      "metadata": {
        "id": "BH7SbcUPWPcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "8obMdgpiV46v",
        "outputId": "a35d4317-a592-40bc-913a-f5780fd05a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-09570c56-235a-40fe-bfe8-79383651b184\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-09570c56-235a-40fe-bfe8-79383651b184\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k65rBCDYKhMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4: Load CSV files into the database tables:**\n",
        "\n",
        "This will populate the database tables with the data from the csv files.  No need to write INSERT statements.\n",
        "\n",
        "You need to make sure the correct files are loaded into the corresponding tables."
      ],
      "metadata": {
        "id": "PQVFAIgNW9I6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def import_csv_to_table(csv_file, table_name):\n",
        "    #opens the file aas read only 'r', doesn't allow the origianl csv to be changed.\n",
        "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "        next(csv_reader)  # Skip header row if present\n",
        "        for row in csv_reader:\n",
        "            #? creates a placeholder for each column in the CSV file. ['?','?','?'] - Join makes it a string so it can then be inserted.\n",
        "            # use of the '?' reduce risk of SQL injection\n",
        "            placeholders = ', '.join(['?' for _ in row])\n",
        "            #Assumes that the CSV and table have the same structure (this could be an issue) Would have to specify column names if different.\n",
        "            sql = f\"INSERT INTO {table_name} VALUES ({placeholders})\"\n",
        "            cursor.execute(sql, row)\n",
        "\n",
        "# Import data from CSV files into the relevant table - Student_Table goes into student table.  teh import_csv_to_table is the function, passing the two values across.\n",
        "try:\n",
        "    import_csv_to_table('olist_customers_dataset.csv', 'olist_customers')\n",
        "    import_csv_to_table('olist_geolocation_dataset.csv', 'olist_geolocation')\n",
        "    import_csv_to_table('olist_order_items_dataset.csv', 'olist_order_items')\n",
        "    import_csv_to_table('olist_order_payments_dataset.csv', 'olist_order_payments')\n",
        "    import_csv_to_table('olist_orders_dataset.csv', 'olist_orders')\n",
        "    import_csv_to_table('olist_products_dataset.csv', 'olist_products')\n",
        "    import_csv_to_table('olist_sellers_dataset.csv', 'olist_sellers')\n",
        "    import_csv_to_table('product_category_name_translation.csv', 'product_category_translation')\n",
        "    conn.commit()\n",
        "    print(\"Data imported successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    conn.rollback()  # Rollback changes if an error occurred\n",
        "\n"
      ],
      "metadata": {
        "id": "ed0T4gXZLTD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5: Check Data has loaded**\n",
        "\n",
        "Query each database table and load the data into a dataframe and display the first 5 lines"
      ],
      "metadata": {
        "id": "d3ozIMAAauOx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ONLY RUN IF YOU NEED TO DELETE THE DATA IN THE TABLES**\n",
        "\n",
        "If you run go back to **STEP 4** and re-run from there."
      ],
      "metadata": {
        "id": "9w8NuN4VcuWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only run if you need to reset the tables without deleting the databae and starting again - then re-run the box previous box.\n",
        "# Delete all data from the tables\n",
        "cursor.execute(\"PRAGMA foreign_keys = OFF\")\n",
        "cursor.execute(\"DELETE FROM olist_customers\")\n",
        "cursor.execute(\"DELETE FROM olist_geolocation\")\n",
        "cursor.execute(\"DELETE FROM olist_order_items\")\n",
        "cursor.execute(\"DELETE FROM olist_order_payments\")\n",
        "cursor.execute(\"DELETE FROM olist_order_reviews\")\n",
        "cursor.execute(\"DELETE FROM olist_orders\")\n",
        "cursor.execute(\"DELETE FROM olist_products\")\n",
        "cursor.execute(\"DELETE FROM olist_sellers\")\n",
        "cursor.execute(\"DELETE FROM product_category_translation\")\n",
        "cursor.execute(\"PRAGMA foreign_keys = ON\")\n",
        "\n",
        "# Commit the changes\n",
        "conn.commit()\n",
        "\n",
        "conn.commit()\n",
        "print(\"Database Deleted - restart.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "4qcmP5_uaSgy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87eaa41a-1380-46ed-80b3-a62a81f3d938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database Deleted - restart.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "customersOrdersValue_df = pd.read_sql_query(\"\"\"\n",
        "SELECT c.customer_id,\n",
        "       COUNT(DISTINCT o.order_id) AS total_orders,\n",
        "       SUM(oi.price) AS total_order_value\n",
        "FROM olist_customers c\n",
        "JOIN olist_orders o ON c.customer_id = o.customer_id\n",
        "JOIN olist_order_items oi ON o.order_id = oi.order_id\n",
        "GROUP BY c.customer_id\n",
        "ORDER BY total_order_value DESC\n",
        "\"\"\", conn)\n",
        "\n",
        "print(customersOrdersValue_df)\n",
        "customersOrdersValue_df.to_csv('customerOrdersValue_df.csv', index=False)\n"
      ],
      "metadata": {
        "id": "VHJfLPeIeU9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show number and value of orders for each customer\n",
        "\n",
        "customersOrdersValue_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "\n",
        "\n",
        "print(customersOrdersValue_df)\n",
        "customersOrdersValue_df.to_csv('customerOrdersValue_df.csv', index=False)"
      ],
      "metadata": {
        "id": "CLPEQyP2fwss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#where do the customers come from - location\n",
        "\n",
        "cLocation_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "print(cLocation_df)\n",
        "cLocation_df.to_csv('cLocation_df.csv', index=False)"
      ],
      "metadata": {
        "id": "XyD4qx8Hf4ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#look at which sellers are selling the most items\n",
        "\n",
        "sellersSales_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "print(sellersSales_df)\n",
        "sellersSales_df.to_csv('sellersSales_df.csv', index=False)\n",
        "\n",
        "#AVG order value for the seller\n",
        "cSellersAVG_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "print(cSellersAVG_df)\n",
        "cSellersAVG_df.to_csv('cSellersAVG_df.csv', index=False)"
      ],
      "metadata": {
        "id": "2GxNywlBf5pn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take a customer that has the most orders and pull out all the individual order items - is there any consistency - are they buying form the same categories every time.\n",
        "customersOrders_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "print(customersOrders_df.head(5))\n",
        "\n",
        "#get customer items fomr order\n",
        "customerItems_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "print(customerItems_df)"
      ],
      "metadata": {
        "id": "bAuxHC11f82A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How are customers paying - which payment methods are used the most\n",
        "\n",
        "paymentMethods_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "print(paymentMethods_df)\n",
        "paymentMethods_df.to_csv('paymentMethods_df.csv', index=False)"
      ],
      "metadata": {
        "id": "sSGXLYG-f_LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if possible, look at the payment methods and location - Identify the area that spends the highest amount - you could look at hteh product categories as well.\n",
        "\n",
        "paymentByLocation_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "# Print formatted output\n",
        "print(paymentByLocation_df)\n",
        "paymentByLocation_df.to_csv('paymentByLocation_df.csv', index=False)"
      ],
      "metadata": {
        "id": "JtBhMZIRgBxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Range of payment by location\n",
        "paymentByLocationRange_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "# Round monetary values for better readability\n",
        "paymentByLocationRange_df[['Total Spent', 'Max Payment', 'Min Payment', 'Payment Range']] = paymentByLocationRange_df[['Total Spent', 'Max Payment', 'Min Payment', 'Payment Range']].round(2)\n",
        "\n",
        "# Print formatted output\n",
        "paymentByLocationRange_df.to_csv('paymentByLocationRange_df.csv',index=False)\n"
      ],
      "metadata": {
        "id": "TNd5GPFFgE8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What's the average order spend in the categories - show the category name in English\n",
        "\n",
        "avgOrderSpendByCategory_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "# Print formatted output\n",
        "print(avgOrderSpendByCategory_df.to_string(index=False))\n",
        "avgOrderSpendByCategory_df.to_csv('avgOrderSpendByCategory_df.csv', index=False)"
      ],
      "metadata": {
        "id": "MujNopwEgKJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get categories in English\n",
        "\n",
        "avgOrderSpendByCategory_df = pd.read_sql_query(\"\"\"\n",
        "\n",
        "\"\"\", conn)\n",
        "\n",
        "# Print formatted output\n",
        "print(avgOrderSpendByCategory_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "tZMMXxdUgMvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}